{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f2f55a-ed1f-4681-9830-a74be6a75663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from netCDF4 import Dataset\n",
    "import os, sys\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from datetime import datetime\n",
    "sys.path.append('/wk171/handsomedong/after_Meeting/')\n",
    "\n",
    "from utility import load_data, count, idxFromDatetime\n",
    "from new_fig import plotLongFig\n",
    "from preprocess.utils_data_collect.terrain_slope import load_shp, mapping, dotProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe06ce-9ac1-48f1-b6cb-f04dc2475cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path = os.path.join(os.getcwd(), \"repro_data\")\n",
    "fileList = [os.path.join(os.getcwd(), \"repro_data\", i) for i in sorted(os.listdir(path)) if \"avg\" in i]\n",
    "# model decision\n",
    "names = ['PONI_Atten', 'PONI_Atten_Windv1']\n",
    "fileList = [fileList[5], fileList[6]]\n",
    "fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba527bd-e601-4751-b151-2a3d7fd4b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AI\n",
    "data_loader = load_data(*fileList, file_num = len(fileList))\n",
    "all_data, target, init_t, = data_loader._return\n",
    "# LOAD TERRAIN\n",
    "filename = \"/bk2/handsomedong/DLRA_database/terrain_slope/GIS_terrain.shp\"\n",
    "df = load_shp(filename)\n",
    "target_map, latList, lonList = df.getMap(\"高程\")\n",
    "new_map, new_lat, new_lon = mapping(latList, lonList, target_map, (120,120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093f9f6-4944-49bb-a031-68b3e1f24930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blurness(data, k_size=3):\n",
    "    # Moving Average\n",
    "    # data shape = [H, W]\n",
    "    pd = k_size//2\n",
    "    tmp = np.pad(data, ((pd,pd), (pd,pd)), 'constant')\n",
    "    tmpp = np.copy(tmp)\n",
    "    for i in range(pd, tmp.shape[0]-pd):\n",
    "        for j in range(pd, tmp.shape[1]-pd):\n",
    "            tmpp[i, j] = tmp[i-pd:i+pd+1, j-pd:j+pd+1].mean()\n",
    "    return tmpp[pd:-pd, pd:-pd]\n",
    "ec_filedir = \"/bk2/handsomedong/DLRA_database/ERA5_reanalysis\"\n",
    "dot = dotProduct(new_map, ec_filedir)\n",
    "# if new_map is loaded from \"高程\", please set is_elevation=True\n",
    "output1, output2 = dot.forward(is_elevation=True)\n",
    "b_slope_x = blurness(output1, k_size=5)\n",
    "b_slope_y = blurness(output2, k_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c455d-0086-41ca-8ce6-ffea179f06c0",
   "metadata": {},
   "source": [
    "# not settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8984e1-14e0-48a7-a63e-f4d83649879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# 3h 累積\n",
    "orig = all_data[0].sum(axis=2).squeeze()\n",
    "hetr = all_data[1].sum(axis=2).squeeze()\n",
    "targ = target.sum(axis=1)\n",
    "\n",
    "orig_head = []; orig_tail = []\n",
    "hetr_head = []; hetr_tail = []\n",
    "targ_head = []; targ_tail = []\n",
    "for i in tqdm(range(0, len(init_t))):\n",
    "    dt = init_t[i]\n",
    "    filepath = os.path.join('/bk2/handsomedong/DLRA_database/ERA5_reanalysis/', str(dt.year), \n",
    "                            str(dt.year)+'{:02d}'.format(dt.month), \n",
    "                            f'era5_{dt.year}{dt.month:02}{dt.day:02}.nc',\n",
    "                            )\n",
    "    data = Dataset(filepath, 'r')\n",
    "    avg_wind = []\n",
    "    for key in ['u', 'v']:\n",
    "        wind = data.variables[key][:] # masked array [24, 20, lat, lon]\n",
    "        wind[np.where(wind.mask!=0)] = np.nan\n",
    "        wind = np.nanmean(wind[:, -7], axis=(-1, -2)) # -7 is 850 hpa\n",
    "        avg_wind.append(wind[dt.hour]) # first u then v\n",
    "    ans = b_slope_x * avg_wind[0] + b_slope_y * avg_wind[1]\n",
    "    \n",
    "    orig_head.extend(orig[i, ans >= 1500])\n",
    "    orig_tail.extend(orig[i, ans <= -1500])\n",
    "    hetr_head.extend(hetr[i, ans >= 1500])\n",
    "    hetr_tail.extend(hetr[i, ans <= -1500])\n",
    "    targ_head.extend(targ[i, ans >= 1500])\n",
    "    targ_tail.extend(targ[i, ans <= -1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d19394e-04e1-493f-8fe2-f2eb210a23a9",
   "metadata": {},
   "source": [
    "# PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89421b1b-5b21-4464-9abb-efe555586808",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.arange(0, 150, 10)\n",
    "head_count = []\n",
    "head_count.append(count(orig_head, threshold=l))\n",
    "head_count.append(count(hetr_head, threshold=l))\n",
    "\n",
    "tail_count = []\n",
    "tail_count.append(count(orig_tail, threshold=l))\n",
    "tail_count.append(count(hetr_tail, threshold=l))\n",
    "print(head_count[0], '\\n', head_count[1])\n",
    "print(tail_count[0], '\\n', tail_count[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0152df-7e1a-485b-91f5-b37cf7c503df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, num='result', figsize=(7, 5.6), dpi=200, facecolor='w')\n",
    "for i in range(len(head_count)):\n",
    "    plt.plot(l,head_count[i],color=\"C\"+str(i), alpha=0.6)\n",
    "    plt.fill_between(l, 0, head_count[i], facecolor=\"C\"+str(i), alpha = 0.5)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bd26fa-0552-4d5f-8f0f-a3bdffac8f21",
   "metadata": {},
   "source": [
    "# RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8258195-517a-4a8d-b673-249646d93e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_thsh = [0, 10, 30, 50, 80, 100, 130]\n",
    "ticks_name = ['0~10', '10~30', '30~50', '50~80', '80~100', '100~130', '>= 130']\n",
    "\n",
    "def cal_itv_rmse(pred:list, target:list, threshold):\n",
    "    diff_thsh = []\n",
    "    for i in range(len(threshold)):\n",
    "        if i == len(threshold)-1:\n",
    "            mask = np.where(np.array(target)>=threshold[i])\n",
    "            rmse = np.mean((np.array(pred)[mask]-np.array(target)[mask])**2)**0.5\n",
    "            diff_thsh.append(rmse)\n",
    "        else:\n",
    "            mask = np.where((np.array(target)>=threshold[i]) & (np.array(target)<threshold[i+1]))\n",
    "            rmse = np.mean((np.array(pred)[mask]-np.array(target)[mask])**2)**0.5\n",
    "            diff_thsh.append(rmse)\n",
    "    return diff_thsh\n",
    "\n",
    "def cal_itv_mape(pred:list, target:list, threshold):\n",
    "    diff_thsh = []\n",
    "    for i in range(len(threshold)):\n",
    "        if i == len(threshold)-1:\n",
    "            mask = np.where(np.array(target)>=threshold[i])\n",
    "            rmse = np.mean(np.abs((np.array(pred)[mask]-np.array(target)[mask]) / np.array(target)[mask]))\n",
    "            diff_thsh.append(rmse)\n",
    "        else:\n",
    "            mask = np.where((np.array(target)>=threshold[i]) & (np.array(target)<threshold[i+1]))\n",
    "            rmse = np.mean(np.abs((np.array(pred)[mask]-np.array(target)[mask]) / np.array(target)[mask]))\n",
    "            diff_thsh.append(rmse)\n",
    "    return diff_thsh\n",
    "\n",
    "ans = []\n",
    "for x, y in zip([orig_head,hetr_head,orig_tail,hetr_tail], [targ_head,targ_head,targ_tail,targ_tail]):\n",
    "    ans.append(cal_itv_rmse(x, y, rain_thsh)) # ans shape [4][len(rain_thsh)]\n",
    "\n",
    "# plot \n",
    "fig, ax = plt.subplots(2,1, figsize=(10, 10), dpi=300, facecolor='w')\n",
    "width = 0.3\n",
    "ax[0].bar(np.arange(len(rain_thsh)), ans[0], width, color='C0', label='orgi')\n",
    "ax[0].bar(np.arange(len(rain_thsh)) + width, ans[1], width, color='C3', label='History')\n",
    "ax[0].set_xticks(np.arange(len(rain_thsh)) + width / 2)\n",
    "ax[0].set_xticklabels(ticks_name)\n",
    "ax[0].legend(['PONI_Atten', 'PONI_Atten_Wind'])\n",
    "ax[0].set_ylabel('threshold (mm)')\n",
    "ax[0].set_title('RMSE')\n",
    "ax[0].grid(axis='y', ls='--')\n",
    "ax[0].set_ylim(0,80)\n",
    "ax[1].bar(np.arange(len(rain_thsh)), ans[2], width, color='C0', label='orgi')\n",
    "ax[1].bar(np.arange(len(rain_thsh)) + width, ans[3], width, color='C3', label='History')\n",
    "ax[1].set_xticks(np.arange(len(rain_thsh)) + width / 2)\n",
    "ax[1].set_xticklabels(ticks_name)\n",
    "ax[1].set_xlabel('mm')\n",
    "ax[1].set_ylabel('threshold (mm)')\n",
    "ax[1].grid(axis='y', ls='--')\n",
    "ax[1].set_title('RMSE')\n",
    "ax[1].set_ylim(0,80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6c1ec3-ffb3-4c35-bac0-47617f5d7540",
   "metadata": {},
   "source": [
    "# case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23545c3f-46b7-4b4b-98a3-54e384c993aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = datetime(2019,9,30,9,50)\n",
    "# dt = datetime(2021,6,4,3,10)\n",
    "dt = datetime(2019,12,30,23,0)\n",
    "# dt = datetime(2018,5,7,16,10)\n",
    "id = idxFromDatetime(init_t, dt)\n",
    "t_len = 5\n",
    "\n",
    "case_target = target.sum(axis=1)\n",
    "case_origin = all_data[0].sum(axis=2).squeeze()\n",
    "case_hetero = all_data[1].sum(axis=2).squeeze()\n",
    "\n",
    "### model axis\n",
    "mat = sio.loadmat('city_lonlat_region5.mat')\n",
    "citylon = mat['citylon']\n",
    "citylat = mat['citylat']\n",
    "del mat\n",
    "latStart = 20; latEnd = 27;\n",
    "lonStart = 118; lonEnd = 123.5;\n",
    "lat = np.linspace(latStart,latEnd,561)\n",
    "lon = np.linspace(lonStart,lonEnd,441)\n",
    "lon, lat = np.meshgrid(lon[215:335], lat[325:445])\n",
    "terrain_lat = np.linspace(20,27,561)[325:445]\n",
    "terrain_lon = np.linspace(118,123.5,441)[215:335]\n",
    "\n",
    "#set colorbar\n",
    "cwbRR = mpl.colors.ListedColormap(['#FFFFFF', '#9CFCFF', '#03C8FF', '#059BFF', '#0363FF',\n",
    "                                   '#059902', '#39FF03', '#FFFB03', '#FFC800', '#FF9500',\n",
    "                                   '#FF0000', '#CC0000', '#990000', '#960099', '#C900CC',\n",
    "                                   '#FB00FF', '#FDC9FF'])\n",
    "bounds = [ 0, 1, 2, 5, 10, 15, 20, 30, 40, 50, 70, 90, 110, 130, 150, 200, 300]\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cwbRR.N)\n",
    "    \n",
    "fig, ax = plt.subplots(4, t_len, figsize=(10, 7), dpi=300, facecolor='w')\n",
    "for i in range(t_len):\n",
    "    idx = id+i\n",
    "    dt = init_t[idx]\n",
    "    filepath = os.path.join('/bk2/handsomedong/DLRA_database/ERA5_reanalysis/', str(dt.year), \n",
    "                            str(dt.year)+'{:02d}'.format(dt.month), \n",
    "                            f'era5_{dt.year}{dt.month:02}{dt.day:02}.nc',\n",
    "                            )\n",
    "    data = Dataset(filepath, 'r')\n",
    "    avg_wind = []\n",
    "    for key in ['u', 'v']:\n",
    "        wind = data.variables[key][:] # masked array [24, 20, lat, lon]\n",
    "        wind[np.where(wind.mask!=0)] = np.nan\n",
    "        wind = np.nanmean(wind[:, -7], axis=(-1, -2)) # -7 is 850 hpa\n",
    "        avg_wind.append(wind[dt.hour]) # first u then v\n",
    "    ans = b_slope_x * avg_wind[0] + b_slope_y * avg_wind[1]\n",
    "    \n",
    "    #\n",
    "    mask_head = ans >= 500\n",
    "    tmp1, tmp2 = np.where(mask_head==True)\n",
    "    \n",
    "    \n",
    "    # plot\n",
    "    ans[ans<0]=0\n",
    "    ax[0,i].plot(citylon,citylat,'k',linewidth=0.6)\n",
    "    ax[0,i].axis([120.6875, 122.1875, 24.0625, 25.5625])# whole area [119, 123, 21, 26]\n",
    "    ax[0,i].set_aspect('equal')\n",
    "    ax[0,i].imshow(ans, norm=None, aspect='equal', cmap='binary',\n",
    "                    extent=[terrain_lon[0],terrain_lon[-1],terrain_lat[-1],terrain_lat[0]],)\n",
    "    ax[0,i].set_xticks([])\n",
    "    ax[0,i].set_yticks([])\n",
    "    \n",
    "    ax[1,i].plot(citylon,citylat,'k',linewidth=0.6)\n",
    "    ax[1,i].axis([120.6875, 122.1875, 24.0625, 25.5625])# whole area [119, 123, 21, 26]\n",
    "    ax[1,i].set_aspect('equal')\n",
    "    ax[1,i].pcolormesh(lon, lat, case_target[idx], edgecolors='none',shading='auto', norm=norm, cmap=cwbRR)\n",
    "    ax[1,i].plot(terrain_lon[tmp2], terrain_lat[tmp1], 'k.', markersize=0.4) \n",
    "    ax[1,i].set_xticks([])\n",
    "    ax[1,i].set_yticks([])\n",
    "    \n",
    "    ax[2,i].plot(citylon,citylat,'k',linewidth=0.6)\n",
    "    ax[2,i].axis([120.6875, 122.1875, 24.0625, 25.5625])# whole area [119, 123, 21, 26]\n",
    "    ax[2,i].set_aspect('equal')\n",
    "    ax[2,i].pcolormesh(lon, lat, case_origin[idx], edgecolors='none',shading='auto', norm=norm, cmap=cwbRR)\n",
    "    ax[2,i].set_xticks([])\n",
    "    ax[2,i].set_yticks([])\n",
    "    \n",
    "    ax[3,i].plot(citylon,citylat,'k',linewidth=0.6)\n",
    "    ax[3,i].axis([120.6875, 122.1875, 24.0625, 25.5625])# whole area [119, 123, 21, 26]\n",
    "    ax[3,i].set_aspect('equal')\n",
    "    ax[3,i].pcolormesh(lon, lat, case_hetero[idx], edgecolors='none',shading='auto', norm=norm, cmap=cwbRR)\n",
    "    ax[3,i].set_xticks([])\n",
    "    ax[3,i].set_yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlra ipykernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
