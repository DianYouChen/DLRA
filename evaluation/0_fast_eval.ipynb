{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12d33611",
   "metadata": {},
   "source": [
    "### Import used modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fbe3cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xc3vancechen/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "### reload magic\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "path, = !pwd\n",
    "path = path.split('/')[:-1]\n",
    "import os, sys, argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "os.environ['ROOT_DATA_DIR']='/work/xc3vancechen/data/DLRA_database'\n",
    "# utils和fast_eval.py不在同一層，所以要sys.path.extend\n",
    "sys.path.extend([\"/\".join(path) + '/training'])\n",
    "\n",
    "from utils.run_utils import (parse_date_end, parse_date_start,\n",
    "                             get_model, checkpoint_parser)\n",
    "from core.model_type import ModelType\n",
    "from core.enum import DataType\n",
    "from data_loaders.data_loader_all_loaded import DataLoaderAllLoaded\n",
    "from utility import performance, idxFromDatetime\n",
    "from plottingFunction import plotFig\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #only 1 GPU後面nn.parellel才不會出事-"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4796c2ae",
   "metadata": {},
   "source": [
    "### customized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0406c7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ckpt name:  /work/xc3vancechen/DLRA/training/checkpoints/RF_10101_41231_mt-18_dt-81_lt-0_tlen-3_ilen-6_sampl-6_teaf-0.5_AdvW-0.01_DisD-3_v-30_epoch=3_val_loss=1.526435_pdsr=0.33_D_auc=1.00_D_pos_acc=0.37_D_neg_acc=0.64.ckpt\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser() #--代表是optional\n",
    "parser.add_argument('--test_start', type=parse_date_start, default=datetime(2021, 12, 31))\n",
    "parser.add_argument('--test_end', type=parse_date_end, default=datetime(2022, 12, 31, 23, 10))\n",
    "parser.add_argument('--ckpt_dir', type=str, \n",
    "                    default=\"/\".join(path) + '/training/checkpoints/')\n",
    "args = parser.parse_args([]) # pulse on the parsers\n",
    "checkpoint = sorted(os.listdir(args.ckpt_dir))\n",
    "checkpoint = [args.ckpt_dir+x for x in checkpoint if 'mt-18_dt-81' in x][0]\n",
    "print('model ckpt name: ',checkpoint)\n",
    "s = args.test_start\n",
    "e = args.test_end\n",
    "input_shape=(540,420)\n",
    "sampling_rate = 6 # examination per hour\n",
    "is_test = True\n",
    "batch_size = 32 # not necessary to be the same as the one training uesd # take \"16\" while evaluating LCL-2\n",
    "num_workers = 8 # for Dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb8fa3e6",
   "metadata": {},
   "source": [
    "### data args, model args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcd77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_lcl = 0\n",
    "kwargs = checkpoint_parser(checkpoint)\n",
    "for k in kwargs.keys():\n",
    "    if k in ['lw','adv_w','AdvW','auc','D_pos_acc','D_neg_acc','D_auc','lssim','lmae', 'teaf']:\n",
    "        kwargs[k] = float(kwargs[k])\n",
    "    elif k not in ['start','end','val_loss','pdsr']:\n",
    "        kwargs[k] = int(kwargs[k])\n",
    "    \n",
    "    if k in ['lcl',]:\n",
    "        idx_lcl = int(kwargs[k])\n",
    "\n",
    "        \n",
    "if 'dt' not in kwargs:\n",
    "    if bool(kwargs.get('jst_rain',0)):\n",
    "        data_type = DataType.RAIN\n",
    "    elif bool(kwargs.get('jst_radar',0)):\n",
    "        data_type = DataType.RADAR\n",
    "    else:\n",
    "        data_type = DataType.RAIN + DataType.RADAR + DataType.ELEVATION\n",
    "else:\n",
    "    data_type=int(kwargs['dt'])\n",
    "\n",
    "data_kwargs = {\n",
    "    'data_type': data_type,\n",
    "    'residual': bool(kwargs.get('res',0)),\n",
    "    'target_offset': int(kwargs.get('toff', 0)),\n",
    "    'target_len': int(kwargs['tlen']),\n",
    "    'input_len': int(kwargs.get('ilen',6)),\n",
    "    'hourly_data': bool(kwargs.get('hrly',0)),\n",
    "    'hetero_data': bool(kwargs.get('hetr',0)),\n",
    "    'sampling_rate': sampling_rate,\n",
    "    'prior_dtype': DataType.NONEATALL,\n",
    "    'random_std': int(kwargs.get('r_std', 0)),\n",
    "    'threshold': 0.5,\n",
    "}\n",
    "model_kwargs = {\n",
    "        'adv_w': float(kwargs.get('adv_w', 0.1)),\n",
    "        'model_type': int(kwargs['mt']),\n",
    "        # For adding locallty connected layers\n",
    "        'LCL':int(kwargs.get('LCL', idx_lcl)),\n",
    "        'dis_d': int(kwargs.get('dis_d', 3)),\n",
    "        'teach_force': int(-1) # for testing\n",
    "    }\n",
    "\n",
    "loss_kwargs = {'type': kwargs['lt'], \n",
    "               'aggregation_mode': kwargs.get('la'), \n",
    "               'kernel_size': kwargs.get('lsz'),\n",
    "               'w': float(kwargs.get('lw', 1)),\n",
    "               'residual_loss':None,\n",
    "               'mae_w':0.1,\n",
    "               'ssim_w':0.02,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e2d36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(idx_lcl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28b2c841",
   "metadata": {},
   "source": [
    "### Load data & model, then evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efdbfcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radar 63.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xxx_radar = np.loadtxt('/work/xc3vancechen/data/DLRA_database/radar_2d_compressed/2022/202207/20220701/20220701_0010.nc.gz', dtype=np.float32)\n",
    "print(\"radar\", np.max(xxx_radar[-1]))\n",
    "# xxx_rain = np.loadtxt('/work/xc3vancechen/data/DLRA_database/rain_compressed_10minFinal/2022/202210/20221028/20221028_0610.nc.gz', dtype=np.float32)\n",
    "# print(\"rain\", xxx_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05101b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loading Train Data] 2021-12-31 00:00:00 2022-12-31 23:10:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:21<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude of Map: 21.9~25.3,Longitude of Map: 120.0~122.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43953/43953 [00:01<00:00, 38560.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude Range: 20.125~26.8625, Longitude Range: 118.125~123.3625 for cropped TW [540x420]\n",
      "Latitude of Map: 21.9~25.3,Longitude of Map: 120.0~122.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43953/43953 [00:01<00:00, 38588.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude Range: 20.125~26.8625, Longitude Range: 118.125~123.3625 for cropped TW [540x420]\n",
      "Latitude of Map: 21.9~25.3,Longitude of Map: 120.0~122.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43953/43953 [00:01<00:00, 38653.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude Range: 20.125~26.8625, Longitude Range: 118.125~123.3625 for cropped TW [540x420]\n",
      "First and last time steps: 2021-12-31 00:10:00 2022-12-31 23:10:00\n",
      "Random time steps: 2022-05-04 23:10:00 2022-02-05 22:10:00 2022-05-12 10:30:00\n",
      "[DataLoaderAllLoaded] Size:52675 Skipped:0\n",
      "[DataLoaderAllLoaded Dtype] RAIN\n",
      "[DataLoaderAllLoaded Dtype] RADAR\n",
      "[DataLoaderAllLoaded Dtype] WIND\n",
      "[DataLoaderAllLoaded Dtype] RAIN_RADAR\n",
      "[DataLoaderAllLoaded Dtype] RAIN_RADAR_WIND\n",
      "[DataLoaderAllLoaded] 2021-12-31 00:00:00<->2022-12-31 23:10:00 ILen:6 TLen:3 Toff:0 TAvgLen:6 Residual:0 Hrly:0 Sampl:6 RandStd:0 Th:0.5\n",
      "Using BalGRUAdvPONI_addponi model\n",
      "[Forecaster_addPONI] TargetLen:3 TeacherForcing:-1\n",
      "[EncoderParams] channel_count:2 Shape:(540, 420)\n",
      "[Discriminator] Downsample:3\n",
      "[PoniModel_addponi W:0.1] Ckp:RF_71231_81231_mt-18_dt-81_lt-0_tlen-3_ilen-6_sampl-6_teaf--1_DisD-3_v-0 \n"
     ]
    }
   ],
   "source": [
    "dataset = DataLoaderAllLoaded(s,e,\n",
    "                              data_kwargs['input_len'],\n",
    "                              data_kwargs['target_len'], \n",
    "                              workers=0,                               \n",
    "                              target_offset=int(kwargs.get('toff',0)),\n",
    "                              data_type=data_type,\n",
    "                              is_train=True,\n",
    "                              is_validation = False,\n",
    "                              is_test = False,\n",
    "                              img_size=input_shape,\n",
    "                              residual=data_kwargs['residual'],\n",
    "                              hourly_data=data_kwargs['hourly_data'],\n",
    "                              hetero_data=data_kwargs['hetero_data'],\n",
    "                              sampling_rate=sampling_rate,\n",
    "                              threshold=data_kwargs['threshold']\n",
    "                             )\n",
    "loader = DataLoader(dataset, batch_size=batch_size,num_workers=num_workers,shuffle=False)\n",
    "\n",
    "model = get_model(\n",
    "        s,\n",
    "        e,\n",
    "        model_kwargs,\n",
    "        loss_kwargs,\n",
    "        data_kwargs,\n",
    "        '',\n",
    "        '',\n",
    "        data_loader_info=dataset.get_info_for_model(),\n",
    "        )\n",
    "\n",
    "# GPU\n",
    "checkpoint = torch.load(checkpoint)\n",
    "_ = model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "# CPU\n",
    "# checkpoint = torch.load(checkpoint, map_location=torch.device('cpu'))\n",
    "# _ = model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d841b853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [03:45<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    #cuda0 = torch.device('cuda:0')\n",
    "    tmp_output = [] \n",
    "    tmp_target = [] \n",
    "    for batch in tqdm(loader):\n",
    "        inp,target,mask = batch # 從dataloader取出來的資料還是tensor.cp\n",
    "        inp = torch.where(inp < 1000, inp, 0.)\n",
    "        inp= inp.cuda() # 將資料直接放到GPU上運算會比較快，在lightning中這行可不寫\n",
    "        target = target.cuda()\n",
    "\n",
    "        if model_kwargs['model_type'] in [18, 19, 20, 21]:\n",
    "            addition = inp[:, :, 1:-1]\n",
    "            inp = torch.cat([inp[:, :, 0:1], inp[:, :, -1:]], dim=2)\n",
    "            output = model(inp, target, addition)\n",
    "        elif model_kwargs['model_type'] in [6, 10] :\n",
    "            output = model(inp)\n",
    "        else:\n",
    "            dummy = torch.zeros_like(target)\n",
    "            output = model(inp, dummy)\n",
    "        \n",
    "        \"\"\"\n",
    "        if model_kwargs['model_type'] == 20:\n",
    "            addition = inp[:, :, 1:-1]\n",
    "            inp = torch.cat([inp[:, :, 0:1], inp[:, :, -1:]], dim=2)\n",
    "            output = model(inp, target, addition)\n",
    "        elif model_kwargs['model_type'] == 10:\n",
    "            output = model(inp)\n",
    "        else:\n",
    "            output = model(inp, target)\n",
    "        \"\"\"\n",
    "        \n",
    "        output[output < 0] = 0\n",
    "        output = output.cpu().numpy()\n",
    "        target = target.cpu().numpy()\n",
    "        tmp_output.append(output)\n",
    "        tmp_target.append(target)\n",
    "                \n",
    "\n",
    "tmp_output = np.concatenate(tmp_output, axis=1)\n",
    "tmp_target = np.concatenate(tmp_target, axis=0)\n",
    "# convert tmp_output shape to [B, 3, H, W]\n",
    "tmp_output = tmp_output.transpose([1,0,2,3])             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a6ceb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 6, 2, 540, 420])\n",
      "tensor(13.2000, device='cuda:0')\n",
      "2021-12-31 01:00:00\n",
      "(8779, 3, 540, 420)\n"
     ]
    }
   ],
   "source": [
    "print(inp.shape)\n",
    "k = inp\n",
    "# k = torch.where(k < 1000, k, 0.)\n",
    "print(torch.max(k))\n",
    "print(dataset.initial_time(0))\n",
    "print(tmp_output.shape)\n",
    "# print(tmp_output[-5,...])\n",
    "# print(np.max(tmp_output[-5,...]))\n",
    "# print(dataset.initial_time(-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28955f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd = performance(tmp_output[:,0], tmp_target[:,0])\n",
    "# pd.showCalResult()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1dcd7cf",
   "metadata": {},
   "source": [
    "## Save as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f09283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "init_t = [dataset.initial_time(i) for i in range(len(dataset))]\n",
    "# create dest_dir\n",
    "if idx_lcl:\n",
    "    dest_path = os.path.join('/work/xc3vancechen/data/model_output/repro_data', \n",
    "                            ModelType.name(model_kwargs['model_type'])+'_mt'+str(kwargs['mt'])+'_dt'+str(kwargs['dt'])+\n",
    "                            '_lcl-1'+'_v-'+str(kwargs['v'])+'_hourly_2022.pkl')\n",
    "else:\n",
    "    dest_path = os.path.join('/work/xc3vancechen/data/model_output/repro_data', \n",
    "                            ModelType.name(model_kwargs['model_type'])+'_mt'+str(kwargs['mt'])+'_dt'+str(kwargs['dt'])+\n",
    "                              '_v-'+str(kwargs['v'])+'_hourly_2022_mk2.pkl')\n",
    "\n",
    "with open(dest_path, 'wb') as handle:\n",
    "    pickle.dump([init_t, tmp_output, tmp_target], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# numpy save\n",
    "# np.savez_compressed(\"/\".join(path) + '/evaluation/PONI_halfAtten_time_BF2', \n",
    "#                     model_output = tmp_output,\n",
    "#                     target = tmp_target,\n",
    "#                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7967b76a",
   "metadata": {},
   "source": [
    "## Save as nc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d62468d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from netCDF4 import Dataset\n",
    "# import numpy.ma as ma\n",
    "\n",
    "# init_t = [dataset.initial_time(i) for i in range(len(dataset))]\n",
    "\n",
    "# for tt in tqdm(range(len(init_t))):\n",
    "\n",
    "#     # if init_t[tt].minute == 0:\n",
    "#     if init_t[tt].day == 7:\n",
    "#         # print(init_t)\n",
    "\n",
    "#         fpath = os.path.join('/work/xc3vancechen/data/model_output'\n",
    "#                               , \"CAPN_nc_files\", f\"{init_t[tt].year}\", f\"{init_t[tt].year}{init_t[tt].month:02}\"\n",
    "#                               , f\"{init_t[tt].year}{init_t[tt].month:02}{init_t[tt].day:02}\")\n",
    "#         fname = os.path.join(fpath, \"deepQPF_\"+f\"{init_t[tt].year}{init_t[tt].month:02}{init_t[tt].day:02}_{init_t[tt].hour:02}{init_t[tt].minute:02}\"+\".nc\")\n",
    "\n",
    "#         if not os.path.exists(os.path.dirname(fname)):\n",
    "#                 os.makedirs(os.path.dirname(fname), exist_ok=True) # os.path.dirname(fname) = fpath\n",
    "\n",
    "#         latStart = 21.45; latEnd = 25.63; \n",
    "#         lonStart = 118.73; lonEnd = 123.05; \n",
    "#         lat = np.linspace(latStart,latEnd,tmp_output.shape[-2])\n",
    "#         lon = np.linspace(lonStart,lonEnd,tmp_output.shape[-1])\n",
    "#         time = np.arange(0,3)\n",
    "        \n",
    "\n",
    "#         f = Dataset(fname, 'w', format = 'NETCDF4')\n",
    "#         f.createDimension('time', len(time))\n",
    "#         f.createDimension('lat', len(lat))  \n",
    "#         f.createDimension('lon', len(lon))\n",
    "#         f.createVariable('output_rr', np.float32, ('time','lat', 'lon'))\n",
    "#         f.createVariable('qperr', np.float32, ('time','lat', 'lon'))\n",
    "#         f.createVariable('time', np.float32, ('time'))\n",
    "#         f.createVariable('lat', np.float32, ('lat'))  \n",
    "#         f.createVariable('lon', np.float32, ('lon'))\n",
    "#         f.variables['time'][:] = np.array(time)\n",
    "#         f.variables['lat'][:] = np.array(lat)\n",
    "#         f.variables['lon'][:] = np.array(lon)\n",
    "#         f.variables['output_rr'][:] = ma.masked_array(tmp_output[tt,:,:,:], mask=None)\n",
    "#         f.variables['qperr'][:] = ma.masked_array(tmp_target[tt,:,:,:], mask=None)\n",
    "#         f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLRA_env_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aff391609ad465dbc90a484b464266ac50636b89ea8b762d68a77262fa9ecb40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
