{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b276a9",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "### reload magic\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "import os, sys\n",
    "import socket, pickle\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "os.environ['ROOT_DATA_DIR']= '/work/xc3vancechen/data/DLRA_database'\n",
    "path = os.getcwd()\n",
    "path = path.split('/')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c693d4",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.cpp_extension import CUDA_HOME\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from core.data_loader_type import DataLoaderType\n",
    "from core.enum import DataType\n",
    "from core.loss_type import BlockAggregationMode, LossType\n",
    "from core.model_type import ModelType\n",
    "from data_loaders.pl_data_loader_module import PLDataLoader\n",
    "from utils.run_utils import get_model, parse_date_end, parse_date_start, parse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453bb170",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(socket.gethostname(), datetime.now().strftime(\"%y-%m-%d-%H:%M:%S\"))\n",
    "print('Python version', sys.version)\n",
    "print('CUDA_HOME', CUDA_HOME)\n",
    "print('CudaToolKit Version', torch.version.cuda)\n",
    "print('torch Version', torch.__version__)\n",
    "print('torchvision Version', torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97775a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser() #--代表是optional\n",
    "# 若在命令列有輸入值，才會進行「type」的運算（預設string）；若無，直接回傳default\n",
    "parser.add_argument('--dloader_type', type=DataLoaderType.from_name, default=DataLoaderType.Native)\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "parser.add_argument('--train_start', type=parse_date_start, default=datetime(2015, 1, 1))\n",
    "parser.add_argument('--train_end', type=parse_date_end, default=datetime(2018, 12, 31, 23, 50))\n",
    "parser.add_argument('--val_start', type=parse_date_start, default=datetime(2021, 1, 1))\n",
    "parser.add_argument('--val_end', type=parse_date_end, default=datetime(2021, 12, 31, 23, 50))\n",
    "parser.add_argument('--loss_kwargs', type=parse_dict, default={})\n",
    "parser.add_argument('--log_dir', type=str, default='logs')\n",
    "parser.add_argument('--data_kwargs', type=parse_dict, default={})\n",
    "parser.add_argument('--model_kwargs', type=parse_dict, default={})\n",
    "parser.add_argument('--checkpoints_path',\n",
    "                    type=str,\n",
    "                    default=('/'.join(path) + '/training/checkpoints/'),\n",
    "                    help='Full path to the directory where model checkpoints are [to be] saved')\n",
    "# 加入Trainer參數\n",
    "parser = Trainer.add_argparse_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52086bcb",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args(['--batch_size','4',\n",
    "                          '--data_kwargs','type:127,sampling_rate:6,target_len:3',\n",
    "                          '--model_kwargs','type:BalGRUAdvIndepenWeightPONI_addponi,teach_force:0.5'\n",
    "                         ]) # 回傳一個args就可以用了\n",
    "print('dloader_type:', args.dloader_type,'\\n\\ndata_kwargs:',args.data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db986f",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "workers = 8\n",
    "#input_shape = (120, 120)\n",
    "input_shape = (540, 420)\n",
    "loss_type = int(args.loss_kwargs.get('type', LossType.WeightedMAE))\n",
    "loss_aggregation_mode = int(args.loss_kwargs.get('aggregation_mode', BlockAggregationMode.MAX))\n",
    "loss_kernel_size = int(args.loss_kwargs.get('kernel_size', 5))\n",
    "residual_loss = bool(int(args.loss_kwargs.get('residual_loss', 0)))\n",
    "mixing_weight = float(args.loss_kwargs.get('w', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c0bee",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "loss_kwargs = {\n",
    "    'type': loss_type,\n",
    "    'aggregation_mode': loss_aggregation_mode,\n",
    "    'kernel_size': loss_kernel_size,\n",
    "    'residual_loss': residual_loss,\n",
    "    'w': mixing_weight\n",
    "}\n",
    "if loss_type in [LossType.SSIMBasedLoss, LossType.NormalizedSSIMBasedLoss]:\n",
    "    loss_kwargs['mae_w'] = float(args.loss_kwargs.get('mae_w', 0.1))\n",
    "    loss_kwargs['ssim_w'] = float(args.loss_kwargs.get('ssim_w', 0.02))\n",
    "\n",
    "data_kwargs = {\n",
    "    'data_type': int(args.data_kwargs.get('type', DataType.RAIN+DataType.RADAR)),\n",
    "    'residual': bool(int(args.data_kwargs.get('residual', 0))),\n",
    "    'target_offset': int(args.data_kwargs.get('target_offset', 0)),\n",
    "    'target_len': int(args.data_kwargs.get('target_len', 3)),\n",
    "    'input_len': int(args.data_kwargs.get('input_len', 6)),\n",
    "    'hourly_data': bool(int(args.data_kwargs.get('hourly_data', 0))),\n",
    "    'hetero_data': bool(int(args.data_kwargs.get('hetero_data', 0))),\n",
    "    'sampling_rate': int(args.data_kwargs.get('sampling_rate', 5)),\n",
    "    'prior_dtype': int(args.data_kwargs.get('prior', DataType.NONEATALL)),\n",
    "    'random_std': int(args.data_kwargs.get('random_std', 0)),\n",
    "    'ith_grid': int(args.data_kwargs.get('ith_grid', -1)),\n",
    "    'pad_grid': int(args.data_kwargs.get('pad_grid', 10)),\n",
    "    'threshold': float(args.data_kwargs.get('threshold', 0.5)),\n",
    "}\n",
    "model_kwargs = {\n",
    "    'adv_w': float(args.model_kwargs.get('adv_w', 0.01)),\n",
    "    'model_type': ModelType.from_name(args.model_kwargs.get('type', 'BalancedGRUAdverserialAttention')),\n",
    "    # For adding locallty connected layers (None: 0, layers:1)\n",
    "    'LCL':int(args.model_kwargs.get('LCL', 0)),\n",
    "    'dis_d': int(args.model_kwargs.get('dis_d', 3)),\n",
    "    'teach_force':float(args.model_kwargs.get('teach_force', 0)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7314b19",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dm = PLDataLoader(\n",
    "    args.train_start,\n",
    "    args.train_end,\n",
    "    args.val_start,\n",
    "    args.val_end,\n",
    "    img_size=input_shape,\n",
    "    dloader_type=args.dloader_type,\n",
    "    **data_kwargs,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6ea08",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    args.train_start,\n",
    "    args.train_end,\n",
    "    model_kwargs,\n",
    "    loss_kwargs,\n",
    "    data_kwargs,\n",
    "    args.checkpoints_path,\n",
    "    args.log_dir,\n",
    "    data_loader_info=dm.model_related_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61ab93",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#logger = TensorBoardLogger(save_dir='logs', name=ModelType.name(model_kwargs['model_type']))\n",
    "# logger = TestTubeLogger(save_dir='logs', name=ModelType.name(model_kwargs['model_type']))\n",
    "# logger.experiment.argparse(args)\n",
    "# logger.experiment.tag({'input_len': data_kwargs['input_len'], 'target_len': data_kwargs['target_len']})\n",
    "# checkpoint_callback = model.get_checkpoint_callback()\n",
    "# trainer = Trainer.from_argparse_args(args, \n",
    "#                                          gpus=1,\n",
    "#                                          max_epochs=30,\n",
    "#                                          fast_dev_run=False, \n",
    "#                                          logger=logger,\n",
    "#                                          callbacks=[checkpoint_callback, EarlyStopping(monitor=\"val_loss\")],\n",
    "#                                         )\n",
    "# trainer.fit(model, dm)  #.fit同時做了train and validation\n",
    "#default max epochs for pl is 1000\n",
    "\n",
    "# if args.evaluate_ckp_path:\n",
    "#     checkpoint = torch.load(args.evaluate_ckp_path)\n",
    "#     _ = model.load_state_dict(checkpoint['state_dict'])\n",
    "#     trainer.test(model, test_dataloaders=dm.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365a419",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(log_model=\"all\")\n",
    "checkpoint_callback = model.get_checkpoint_callback()\n",
    "trainer = Trainer.from_argparse_args(args, \n",
    "                                         gpus=1,\n",
    "                                         max_epochs=30,\n",
    "                                         fast_dev_run=False,\n",
    "                                         logger=wandb_logger,\n",
    "                                         callbacks=[checkpoint_callback, EarlyStopping(monitor=\"val_loss\")],\n",
    "                                        )\n",
    "trainer.fit(model, dm)  #.fit同時做了train and validation\n",
    "#default max epochs for pl is 1000\n",
    "\n",
    "# if args.evaluate_ckp_path:\n",
    "#     checkpoint = torch.load(args.evaluate_ckp_path)\n",
    "#     _ = model.load_state_dict(checkpoint['state_dict'])\n",
    "#     trainer.test(model, test_dataloaders=dm.val_dataloader())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLRA_env_v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a9d9470aad714aac9887a3d7e6c0eed78a59a15622267c3a43768fe99f5bfe2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
